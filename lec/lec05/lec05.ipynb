{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d49d679",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
    "\n",
    "<h1 class=\"cal cal-h1\">Lecture 05: Density Estimation and GMMs â€“ CS 189, Fall 2025</h1>\n",
    "\n",
    "\n",
    "In this lecture we will explore the implementation of the Gaussian Mixture Model (GMM) using the Expectation-Maximization (EM) algorithm. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552e7282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly import figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "colors = px.colors.qualitative.Plotly\n",
    "px.defaults.width = 800\n",
    "from ipywidgets import HBox\n",
    "import numpy as np\n",
    "pd.set_option('plotting.backend', 'plotly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832977bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the images folder if it doesn't exist\n",
    "import os\n",
    "if not os.path.exists(\"images\"):\n",
    "    os.makedirs(\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5a4118",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uncomment for HTML Export\n",
    "# import plotly.io as pio\n",
    "# pio.renderers.default = \"notebook_connected\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9419ae",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
    "<h2 class=\"cal cal-h2\">The Gaussian Distribution</h2>\n",
    "\n",
    "\n",
    "The probability density function of a univariate Gaussian distribution with mean $\\mu$ and variance $\\sigma^2$ is given by:\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa82990a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "mean = 0 \n",
    "variance = .7\n",
    "x = np.linspace(-4, 4, 100)\n",
    "p = norm.pdf(x, loc=mean, scale=np.sqrt(variance)) # scale = standard deviation, loc = mean\n",
    "fig = px.line(x=x, y=p, title=f\"Standard Normal Distribution (mean={mean}, variance={variance})\",\n",
    "        labels={\"x\": \"x\", \"y\": \"p(x)\"}, width = 700, height = 400)\n",
    "# fig.write_image(\"images/standard_normal.pdf\", scale=2, height=400, width=700)\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdece24",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
    "<h3 class=\"cal cal-h3\">Multivariate Normal Distribution</h3>\n",
    "\n",
    "The equation for the multivariate normal is given by:\n",
    "$$\n",
    "f(\\mathbf{x}) = \\frac{1}{\\sqrt{(2\\pi)^D|\\Sigma|}} \\exp\\left(-\\frac{1}{2}(\\mathbf{x}-\\mu)^T\\Sigma^{-1}(\\mathbf{x}-\\mu)\\right)\n",
    "$$\n",
    "where $\\mathbf{x}$ is a $D$-dimensional random vector, $\\mu$ is the mean vector, and $\\Sigma$ is the covariance matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df15c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mv_normal_pdf(X, mu, Sigma):\n",
    "    \"\"\"Compute the multivariate normal density at points X.\"\"\"\n",
    "    d = X.shape[1]\n",
    "    X_centered = X - mu\n",
    "    Sigma_inv = np.linalg.inv(Sigma)\n",
    "    norm_const = 1 / np.sqrt((2 * np.pi) ** d * np.linalg.det(Sigma))\n",
    "    exp_term = np.exp(-0.5 * np.sum(X_centered @ Sigma_inv * X_centered, axis=1))\n",
    "    return norm_const * exp_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6931a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.array([1, 0])\n",
    "Sigma = np.array([[3, 0.4], [0.4, 2]])\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "normal = multivariate_normal(mean=mu, cov=Sigma)\n",
    "normal.pdf(np.array([[1, 0.5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db63458",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_normal_pdf(np.array([[1, 0.5]]), mu, Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d50cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bivariate_normal(mu, Sigma, fig=None):\n",
    "    from scipy.stats import multivariate_normal\n",
    "    normal = multivariate_normal(mean=mu, cov=Sigma)\n",
    "    u = np.linspace(-9, 9, 100)\n",
    "    X = np.array(np.meshgrid(u,u)).reshape(2,-1).T\n",
    "    Z = normal.pdf(X)\n",
    "    if fig is None:\n",
    "        fig = make_subplots(rows=1, cols=2,\n",
    "                            specs=[[{'type': 'surface'}, {'type': 'contour'}]],)\n",
    "    fig.add_surface(x=X[:,0].reshape(100,100), y=X[:,1].reshape(100,100), \n",
    "                    z=Z.reshape(100,100), colorscale='Viridis',\n",
    "                    contours=dict(z=dict(show=True, size=.01, start=0, end=0.3)), row=1, col=1)\n",
    "    fig.add_contour(x=u, y=u, z=Z.reshape(100,100), colorscale='Viridis',\n",
    "                    line_smoothing=1.3,\n",
    "                    #contours_coloring='lines',\n",
    "                    showscale=False,\n",
    "                    row=1, col=2\n",
    "                    )\n",
    "    fig.update_layout(width=900, height=500)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ce0ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.array([1, 0])\n",
    "Sigma = np.array([[3, 0.4], [0.4, 2]])\n",
    "plot_bivariate_normal(mu, Sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54f9697",
   "metadata": {},
   "source": [
    "The following interactive plot will only work in a Jupyter notebook environment. It allows you to visualize how changing the mean and covariance matrix affects the shape of the bivariate normal distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f95f677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interactive_output, FloatSlider, HBox, VBox, widgets\n",
    "\n",
    "u = np.linspace(-9, 9, 100)\n",
    "X = np.array(np.meshgrid(u,u)).reshape(2,-1).T\n",
    "normal = multivariate_normal(mean=mu, cov=Sigma)\n",
    "Z = normal.pdf(X)\n",
    "fig1 = go.FigureWidget()\n",
    "fig1.add_surface(x=X[:,0].reshape(100,100), y=X[:,1].reshape(100,100), \n",
    "                z=Z.reshape(100,100), colorscale='Viridis',\n",
    "                contours=dict(z=dict(show=True, size=.01, start=0, end=0.3)))\n",
    "fig1.update_layout(width=600, height=500)\n",
    "fig2 = go.FigureWidget()\n",
    "fig2.add_contour(x=u, y=u, z=Z.reshape(100,100), colorscale='Viridis',\n",
    "                line_smoothing=1.3)\n",
    "fig2.update_layout(width=400, height=500)\n",
    "\n",
    "mu1 = FloatSlider(min=-5, max=5, step=0.1, value=1, description='mu1')\n",
    "mu2 = FloatSlider(min=-5, max=5, step=0.1, value=0, description='mu2')\n",
    "sigma11 = FloatSlider(min=0.1, max=5, step=0.1, value=3, description='sigma11')\n",
    "sigma22 = FloatSlider(min=0.1, max=5, step=0.1, value=2, description='sigma22')\n",
    "sigma12 = FloatSlider(min=-3, max=3, step=0.1, value=0.4, description='sigma12')\n",
    "\n",
    "\n",
    "def update(mu1, mu2, sigma11, sigma22, sigma12):\n",
    "    mu = np.array([mu1, mu2])\n",
    "    Sigma = np.array([[sigma11, sigma12], [sigma12, sigma22]])\n",
    "    normal = multivariate_normal(mean=mu, cov=Sigma)\n",
    "    Z = normal.pdf(X).reshape(100,100)\n",
    "    with fig1.batch_update():\n",
    "        fig1.data[0].z = Z\n",
    "    with fig2.batch_update():\n",
    "        fig2.data[0].z = Z\n",
    "\n",
    "interactive_output(update, {\n",
    "    'mu1': mu1, 'mu2': mu2,\n",
    "    'sigma11': sigma11, 'sigma22': sigma22, 'sigma12': sigma12\n",
    "})\n",
    "\n",
    "HBox([VBox([mu1, mu2, sigma11, sigma22, sigma12]), fig1, fig2],  \n",
    "     layout=widgets.Layout(align_items='center'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f35dc62",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "---\n",
    "Return to Lecture\n",
    "\n",
    "---\n",
    "\n",
    "<br><br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedd1740",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
    "\n",
    "<h2 class=\"cal cal-h2\">The Bike Dataset</h2>\n",
    "\n",
    "As with the previous lecture, we will use Professor Gonzalez's bike ride dataset to illustrate the concepts. The dataset contains the speed and length of bike rides taken with different bikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebab80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bikes = pd.read_csv(\"speed_length_data.csv\")\n",
    "bikes = pd.read_csv(\"https://eecs189.org/fa25/resources/assets/lectures/lec04/speed_length_data.csv\")\n",
    "bikes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8739f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.plot.scatter(x='Speed', y='Length', title='Speed vs Length of Bike Segments', \n",
    "                   height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cb6b75",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
    "<h2 class=\"cal cal-h2\">The Gaussian Mixture Model</h2>\n",
    "\n",
    "\n",
    "A Gaussian Mixture Model (GMM) is a probabilistic model that assumes all the data points are generated from a mixture of several Gaussian distributions:\n",
    "\n",
    "$$\n",
    "p(x \\, \\vert \\, \\pi, \\mu, \\Sigma) = \\sum_{k=1}^{K} \\pi_k \\, \\mathcal{N}(x | \\mu_k, \\Sigma_k)\n",
    "$$\n",
    "\n",
    "Just as with the K-Means model, we can use the `GaussianMixture` class from `sklearn.mixture` to fit a GMM to our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc8689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "# Create a Gaussian Mixture Model with 4 components\n",
    "gmm = GaussianMixture(n_components=4, random_state=42, )\n",
    "# Fit the model to the data\n",
    "gmm.fit(bikes[['Speed', 'Length']])\n",
    "# Get the cluster labels\n",
    "bikes['scikit gmm'] = gmm.predict(bikes[['Speed', 'Length']]).astype(str)\n",
    "bikes['prob'] = gmm.predict_proba(bikes[['Speed', 'Length']]).max(axis=1)\n",
    "bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eb0829",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = gmm.means_\n",
    "Sigma = [np.linalg.inv(p) for p in gmm.precisions_]\n",
    "p = gmm.weights_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7052a3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm_surface(mu, Sigma, p, u_pts, v_pts):\n",
    "    from scipy.stats import multivariate_normal\n",
    "    u, v = np.meshgrid(u_pts, v_pts)\n",
    "    X_pts = np.array([u.flatten(), v.flatten()]).T\n",
    "    Z = np.zeros(X_pts.shape[0])\n",
    "    for k in range(len(p)):\n",
    "        Z += p[k] * multivariate_normal(mu[k], Sigma[k]).pdf(X_pts)\n",
    "    return go.Contour(x=u_pts, y=v_pts, z=Z.reshape(u.shape), \n",
    "                      colorscale='Viridis',\n",
    "                      colorbar=dict(x=1.05, y=0.35, len=0.75)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0def8340",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 100\n",
    "speed_pts = np.linspace(bikes['Speed'].min()-3, bikes['Speed'].max()+3, num_points)\n",
    "length_pts = np.linspace(bikes['Length'].min()-3, bikes['Length'].max()+3, num_points)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(gmm_surface(mu, Sigma, p, speed_pts, length_pts))\n",
    "fig.update_layout(width=800, height=800)\n",
    "fig.add_traces(px.scatter(bikes, x='Speed', y='Length', color='scikit gmm').data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3972309e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(bikes, x='Speed', y='Length', symbol='scikit gmm', \n",
    "           size='prob', color=\"scikit gmm\", title='GMM Clustering',\n",
    "           color_continuous_scale=\"Viridis_r\", size_max=15)\n",
    "fig.update_layout(width=800, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115a062a",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "---\n",
    "Return to Lecture\n",
    "\n",
    "---\n",
    "\n",
    "<br><br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4242dabe",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
    "<h2 class=\"cal cal-h2\">Ancestor Sampling for the GMM</h2>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ab5f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ancestor Sampling to create a synthetic dataset\n",
    "np.random.seed(42)\n",
    "N = 100\n",
    "\n",
    "mu = np.array([-1, 2, 5])\n",
    "pi = np.array([0.2, 0.5, 0.3])\n",
    "Sigma = np.array([0.2, 0.5, .1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ae936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.random.choice(len(mu), size=N, p=pi)\n",
    "x = np.random.normal(mu[z], np.sqrt(Sigma[z]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5901449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood = np.sum(np.log(np.sum(\n",
    "    pi[z] * norm.pdf(x[:, None], loc=mu[z], scale=np.sqrt(Sigma[z])), \n",
    "    axis=1 )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e525780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort for better visualization\n",
    "ind = z.argsort()\n",
    "z = z[ind]\n",
    "x = x[ind]\n",
    "\n",
    "fig = px.scatter(x=x, y=np.random.rand(N)/20,  \n",
    "                 title=f'Synthetic Dataset from GMM (Log Likelihood: {log_likelihood:.2f})',\n",
    "                 opacity = 0.7,\n",
    "                 color=z.astype(str), labels={'color': 'True Cluster'}, height=400)\n",
    "u = np.linspace(-4, 9, 1000)\n",
    "df = pd.DataFrame({'x': u})\n",
    "for k in range(len(mu)):\n",
    "    df[f'p{k}'] = pi[k] * norm.pdf(u, loc=mu[k], scale=np.sqrt(Sigma[k]))\n",
    "df['p'] = df[[f'p{k}' for k in range(len(mu))]].sum(axis=1)\n",
    "fig.add_traces(px.line(df, x='x', y=df.columns[1:], labels={'y': 'Density'}).data)\n",
    "fig.update_layout(width=800, height=400)\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef6d33e",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "---\n",
    "Return to Lecture\n",
    "\n",
    "---\n",
    "\n",
    "<br><br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66338c58",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
    "<h2 class=\"cal cal-h2\">Implementing the GMM using the EM Algorithm</h2>\n",
    "\n",
    "Directly maximizing the log-likelihood function is challenging:\n",
    "\n",
    "\\begin{align*}\n",
    "\\log p\\left(\\mathcal{D} \\,\\vert\\, \\mu, \\Sigma \\right) \n",
    "& = \\log \\left( \\prod_{n=1}^{N} \\sum_{k=1}^{K} \\pi_k \\, \\mathcal{N}(x_n | \\mu_k, \\Sigma_k) \\right) \\\\\n",
    "& = \\sum_{n=1}^{N} \\log \\left(\\sum_{k=1}^{K} \\pi_k \\, \\mathcal{N}(x_n | \\mu_k, \\Sigma_k) \\right) \\\\\n",
    "\\end{align*}\n",
    "\n",
    "because of the summation inside of the logarithm. Instead, we use the Expectation-Maximization (EM) algorithm to iteratively optimize the parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db380545",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
    "<h3 class=\"cal cal-h3\">The Initialization Step</h3>\n",
    "\n",
    "\n",
    "A typical way to initialize GMM models is to start with k-means clustering to find the initial means of the Gaussian components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5cc670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "def initialize_gmm(x, K):\n",
    "    N, D = x.shape\n",
    "    kmeans = KMeans(n_clusters=K)\n",
    "    kmeans.fit(x)\n",
    "    mu = kmeans.cluster_centers_\n",
    "    Sigma = np.array([np.eye(D) for _ in range(K)])\n",
    "    p = np.ones(K) / K\n",
    "    return mu, Sigma, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa44f075",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, Sigma, p = initialize_gmm(bikes[['Speed', 'Length']], 4)\n",
    "display(mu, Sigma, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97a075b",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
    "<h3 class=\"cal cal-h3\">The (E)xpectation -Step</h3>\n",
    "\n",
    "In the E-step, we compute the responsibilities, which represent the probability that each data point belongs to each Gaussian component given the current parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e92ece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_step(x, mu, Sigma, p):\n",
    "    \"\"\"E-step of the EM algorithm.\n",
    "    Computes the posterior probabilities of the latent variables (z) given the data.\n",
    "    \"\"\"\n",
    "    N, D = x.shape\n",
    "    K = len(p)\n",
    "    assert(Sigma.shape == (K, D, D))\n",
    "    assert(mu.shape == (K,D))        \n",
    "    p_z_given_x = np.zeros((N, K))\n",
    "    for k in range(K):\n",
    "        p_z_given_x[:, k] = p[k] * multivariate_normal(mu[k], Sigma[k]).pdf(x)\n",
    "    p_z_given_x /= p_z_given_x.sum(axis=1, keepdims=True) # Normalize to get probabilities\n",
    "    return p_z_given_x  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ce00ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_z_given_x = E_step(bikes[['Speed', 'Length']], mu, Sigma, p)\n",
    "p_z_given_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f099a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_z_given_x.sum(axis=1)  # Each row should sum to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626a95b7",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
    "<h3 class=\"cal cal-h3\">The (M)aximization -Step</h3>\n",
    "\n",
    "In this step, we update the parameters of the Gaussian components based on the responsibilities computed in the E-step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212996f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_step(x, p_z_given_x):\n",
    "    \"\"\"M-step of the EM algorithm.\n",
    "    Updates the parameters (mu, sigma, p) based on the posterior probabilities.\n",
    "    \"\"\"\n",
    "    N, D = x.shape\n",
    "    N, K = p_z_given_x.shape\n",
    "    mu_new = np.zeros((K, D))\n",
    "    Sigma_new = np.zeros((K, D, D))\n",
    "    p_new = np.zeros(K)\n",
    "    \n",
    "    for k in range(K):\n",
    "        N_k = p_z_given_x[:, k].sum()\n",
    "        mu_new[k, :] = p_z_given_x[:, k] @ x / N_k\n",
    "        Sigma_new[k, :, :] = (p_z_given_x[:, k] * (x - mu_new[k, :]).T @ (x - mu_new[k, :])) / N_k\n",
    "        Sigma_new[k, :, :] += 1e-3 * np.eye(D)  # Regularization\n",
    "        p_new[k] = N_k / N\n",
    "\n",
    "    return mu_new, Sigma_new, p_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79aab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_step(bikes[['Speed', 'Length']], p_z_given_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee0fc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def em_algorithm(x, K, max_iters=100, initial_variance=100):\n",
    "    D = 2\n",
    "    p = np.ones(K) / K\n",
    "    # sample initial mu from data\n",
    "    mu, Sigma, p = initialize_gmm(x, K)\n",
    "    mu = mu + np.random.randn(*mu.shape) * 3\n",
    "    soln_path = [(mu, Sigma, p)]\n",
    "    for i in range(max_iters):\n",
    "        p_z_given_x = E_step(x, mu, Sigma, p)\n",
    "        mu, Sigma, p = M_step(x, p_z_given_x)\n",
    "        soln_path.append((mu, Sigma, p))\n",
    "    return mu, Sigma, p, soln_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b5f690",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, Sigma, p, soln_path = em_algorithm(bikes[['Speed', 'Length']].values, \n",
    "                                       K=4, \n",
    "                                       max_iters=50)\n",
    "print(\"mu\", mu)\n",
    "print(\"Sigma\", Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b53bf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 100\n",
    "speed_pts = np.linspace(bikes['Speed'].min()-3, bikes['Speed'].max()+3, num_points)\n",
    "length_pts = np.linspace(bikes['Length'].min()-3, bikes['Length'].max()+3, num_points)\n",
    "\n",
    "mu, Sigma, p = soln_path[-1]\n",
    "fig = go.Figure()\n",
    "fig.add_trace(gmm_surface(mu, Sigma, p, speed_pts, length_pts))\n",
    "fig.update_layout(width=800, height=800)\n",
    "fig.add_traces(px.scatter(bikes, x='Speed', y='Length', color='scikit gmm').data)\n",
    "fig.add_scatter(x=mu[:,0], y=mu[:,1], mode='markers', marker=dict(color='black', size=10), name='Centers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6632e283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import  IntSlider\n",
    "np.random.seed(42)\n",
    "mu, Sigma, p, soln_path = em_algorithm(bikes[['Speed', 'Length']].values, \n",
    "                                       K=4, \n",
    "                                       max_iters=100)\n",
    "num_points = 100\n",
    "speed_pts = np.linspace(bikes['Speed'].min()-3, bikes['Speed'].max()+3, num_points)\n",
    "length_pts = np.linspace(bikes['Length'].min()-3, bikes['Length'].max()+3, num_points)\n",
    "\n",
    "mu, Sigma, p = soln_path[0]\n",
    "fig = go.FigureWidget()\n",
    "fig.add_trace(gmm_surface(mu, Sigma, p, speed_pts, length_pts))\n",
    "fig.update_layout(width=800, height=800)\n",
    "fig.add_traces(px.scatter(bikes, x='Speed', y='Length', color='scikit gmm').data)\n",
    "fig.add_scatter(x=mu[:,0], y=mu[:,1], mode='markers', marker=dict(color='black', size=10), name='Centers')\n",
    "\n",
    "def update(step):\n",
    "    mu, Sigma, p = soln_path[step]\n",
    "    with fig.batch_update():\n",
    "        fig.data[0].z = gmm_surface(mu, Sigma, p, speed_pts, length_pts).z\n",
    "    with fig.batch_update():\n",
    "        fig.data[-1].x = mu[:, 0]\n",
    "        fig.data[-1].y = mu[:, 1]\n",
    "step_slider = IntSlider(min=0, max=len(soln_path)-1, step=1, value=0, description='Step')\n",
    "interactive_output(update, {'step': step_slider}) \n",
    "VBox([fig, step_slider])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69edde49",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
    "<h2 class=\"cal cal-h2\">Issue with the MLE of the GMM</h2>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba4eb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ancestor Sampling to create a synthetic dataset\n",
    "np.random.seed(42)\n",
    "N = 100\n",
    "\n",
    "mu = np.array([-1, 2, 5])\n",
    "pi = np.array([0.2, 0.5, 0.3])\n",
    "Sigma = np.array([0.2, 0.5, .1])\n",
    "\n",
    "z = np.random.choice(len(mu), size=N, p=pi)\n",
    "x = np.random.normal(mu[z], np.sqrt(Sigma[z]))\n",
    "\n",
    "log_likelihood = np.sum(np.log(np.sum(\n",
    "    pi[z] * norm.pdf(x[:, None], loc=mu[z], scale=np.sqrt(Sigma[z])), \n",
    "    axis=1 )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76adca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort for better visualization\n",
    "ind = z.argsort()\n",
    "z = z[ind]\n",
    "x = x[ind]\n",
    "\n",
    "fig = px.scatter(x=x, y=np.random.rand(N)/20,  \n",
    "                 title=f'Synthetic Dataset from GMM (Log Likelihood: {log_likelihood:.2f})',\n",
    "                 opacity = 0.7,\n",
    "                 color=z.astype(str), labels={'color': 'True Cluster'}, height=400)\n",
    "u = np.linspace(-4, 9, 1000)\n",
    "df = pd.DataFrame({'x': u})\n",
    "for k in range(len(mu)):\n",
    "    df[f'p{k}'] = pi[k] * norm.pdf(u, loc=mu[k], scale=np.sqrt(Sigma[k]))\n",
    "fig.add_traces(px.line(df, x='x', y=df.columns[1:], labels={'y': 'Density'}).data)\n",
    "fig.update_layout(width=800, height=400)\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54c1983",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.array([x.min(), x.mean(), x.max()])\n",
    "Sigma = np.array([1e-100, 10, 1e-100])\n",
    "pi = np.array([0.3, 0.4, 0.3])\n",
    "\n",
    "log_likelihood = np.sum(np.log(np.sum(\n",
    "    pi[z] * norm.pdf(x[:, None], loc=mu[z], scale=np.sqrt(Sigma[z])), \n",
    "    axis=1 )))\n",
    "\n",
    "fig = px.scatter(x=x, y=np.random.rand(N)/20,  \n",
    "                 title=f'Extreme Values from GMM (Log Likelihood: {log_likelihood:.2f})',\n",
    "                 opacity = 0.7,\n",
    "                 color=z.astype(str), labels={'color': 'True Cluster'}, height=400)\n",
    "u = np.linspace(-4, 9, 100)\n",
    "u = np.append(u, mu)\n",
    "u.sort()\n",
    "df = pd.DataFrame({'x': u})\n",
    "for k in range(len(mu)):\n",
    "    df[f'p{k}'] = pi[k] * norm.pdf(u, loc=mu[k], scale=np.sqrt(Sigma[k]))\n",
    "fig.add_traces(px.line(df, x='x', y=df.columns[1:], labels={'y': 'Density'}).data)\n",
    "fig.update_layout(width=800, height=400)\n",
    "fig.update_layout(yaxis_range=[0, 1])\n",
    "\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_3_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
